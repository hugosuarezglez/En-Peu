{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a470b379",
   "metadata": {},
   "source": [
    "Ahora hacemos un análisis de correlación de las variables. Como hay variables numéricas y categóricas, haremos distintos análisis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08efe87a",
   "metadata": {},
   "source": [
    "Primero analizaremos la correlación entre variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d5b0c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numericas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3548/1795097424.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Usamos solo las variables numéricas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcateg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'CUS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'OC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mnumericas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumericas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcateg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Excluir las coordenadas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numericas' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"data_stored.csv\")\n",
    "\n",
    "# Usamos solo las variables numéricas\n",
    "categ = ['CUS', 'OC']\n",
    "numericas = numericas.drop(columns=categ, errors='ignore')\n",
    "\n",
    "# Excluir las coordenadas\n",
    "coord = ['POINT_X', 'POINT_Y']\n",
    "numericas = numericas.drop(columns=coord, errors='ignore')\n",
    "\n",
    "# Matriz de correlación\n",
    "matriz_cor = numericas.corr()\n",
    "print(\"Matriz de correlación:\")\n",
    "print(matriz_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualizar la matriz como heatmap\n",
    "print(\"\\nGenerando Heatmap de la matriz de correlación...\")\n",
    "plt.figure(figsize=(10, 8)) # Ajusta el tamaño de la figura para una mejor visualización\n",
    "\n",
    "mask = np.triu(np.ones_like(matriz_cor, dtype=bool))\n",
    "\n",
    "sns.heatmap(matriz_cor, mask=mask, annot=True, cmap='coolwarm', fmt=\".2f\",\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 8}) # fmt=\".2f\" para 2 decimales, annot=True para valores\n",
    "plt.title(\"Matriz de Correlación de Variables Numéricas\", fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right') # Rotar etiquetas del eje X para mejor legibilidad\n",
    "plt.yticks(rotation=0) # Asegurarse que etiquetas del eje Y no roten\n",
    "plt.tight_layout() # Ajustar el diseño para que todo quepa\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df9f28",
   "metadata": {},
   "source": [
    "Vemos que las variables A y CIB tienen una correlación mayor a 80%, y que DBB y DOB tienen una correlación mayor al 70%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc80d5",
   "metadata": {},
   "source": [
    "Ahora queremos ver si las variables categóricas están correlacionadas entre sí. Esto no puede hacerse directamente, entonces se hace un test de Cramer's V, que mide la fuerza de asociación entre dos variables categóricas. El valor varía entre 0 (sin asociación) y 1 (asociación total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319767a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency # Para el test de chi-cuadrado\n",
    "\n",
    "categoricas = data[[\"CUS\", \"OC\"]]\n",
    "\n",
    "def cramers_v(x, y):\n",
    "        confusion_matrix = pd.crosstab(x, y)\n",
    "        chi2, p_val, dof, expected = chi2_contingency(confusion_matrix)\n",
    "        n = confusion_matrix.sum().sum()\n",
    "        r, k = confusion_matrix.shape\n",
    "        min_dim = min(k - 1, r - 1)\n",
    "        if n == 0 or min_dim == 0:\n",
    "            return 0.0\n",
    "        phi2 = chi2 / n\n",
    "        v = np.sqrt(phi2 / min_dim)\n",
    "        return v\n",
    "\n",
    "cramer_v_result = cramers_v(categoricas['CUS'], categoricas['OC'])\n",
    "print(f\"Cramér's V entre CUS y OC: {cramer_v_result:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2bbcf",
   "metadata": {},
   "source": [
    "El resultado muestra una asociación moderada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc3937",
   "metadata": {},
   "source": [
    "Una vez más, no se puede ver la correlación entre variables categóricas y numéricas, pero se puede comprobar la diferencia de las medias entre grupos. Para ello usamos el test de Kruskal Wallis, que es una versión del ANOVA que no asume normalidad, para variables categóricas de más de dos grupos. \n",
    "El test nos indicará el valor de p con la hipótesis de que las medias (de una variable numérica) entre los grupos de la variable categórica son diferentes. Esto nos indica si el hecho de pertenecer a un grupo o a otro afecta a la variable numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20aa19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "\n",
    "kruskal_results = {}\n",
    "\n",
    "\n",
    "def get_kruskal_pvalue(df, cat_col, num_col):\n",
    "    \"\"\"\n",
    "    Prepara los datos y ejecuta el test de Kruskal-Wallis para un par de variables.\n",
    "    Retorna el p-valor o np.nan si el test no se puede realizar.\n",
    "    \"\"\"\n",
    "    # Nos aseguramos de que la variable categórica tenga al menos 2 grupos únicos.\n",
    "    # Ya que el usuario indica que los datos están limpios, no necesitamos un .dropna() global aquí,\n",
    "    # pero sí para asegurarnos que cada grupo sea no vacío al pasarlo a kruskal.\n",
    "    unique_categories = df[cat_col].unique()\n",
    "\n",
    "    # Si hay menos de 2 categorías únicas, el test no tiene sentido.\n",
    "    if len(unique_categories) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # Preparamos los datos numéricos agrupados por categoría.\n",
    "    # kruskal requiere cada grupo como un argumento separado.\n",
    "    # El .dropna() aquí es para asegurar que los arrays pasados a kruskal no contengan NaNs\n",
    "    # dentro de los grupos, aunque los datos principales se asuman limpios.\n",
    "    groups_data = [df[num_col][df[cat_col] == category].dropna().values\n",
    "                   for category in unique_categories]\n",
    "\n",
    "    # Filtramos grupos que puedan haber quedado vacíos después de la extracción y el dropna()\n",
    "    valid_groups = [group for group in groups_data if len(group) > 0]\n",
    "\n",
    "    # Kruskal-Wallis necesita al menos 2 grupos con datos\n",
    "    if len(valid_groups) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        # Ejecutamos el test de Kruskal-Wallis. El '*' desempaqueta la lista 'valid_groups'.\n",
    "        stat, p_value = kruskal(*valid_groups)\n",
    "        return p_value\n",
    "    except ValueError as e:\n",
    "        # Captura errores comunes (ej. si todos los valores en un grupo son idénticos)\n",
    "        # print(f\"  Error interno de scipy.kruskal para {cat_col} vs {num_col}: {e}\")\n",
    "        return np.nan # Retornamos NaN en caso de error para indicar que no se pudo calcular\n",
    "\n",
    "# Bucle principal para ejecutar el test en todas las combinaciones\n",
    "for cat_var in categorical_vars:\n",
    "    # Comprobación de que la variable categórica es válida para agrupar\n",
    "    # (ej. tiene más de un valor único en el DataFrame original)\n",
    "    if data[cat_var].nunique() < 2:\n",
    "        print(f\"Advertencia: '{cat_var}' tiene menos de 2 grupos únicos. Saltando tests con esta variable.\")\n",
    "        continue\n",
    "\n",
    "    for num_var in numeric_vars:\n",
    "        p_val = get_kruskal_pvalue(data, cat_var, num_var)\n",
    "\n",
    "        if not np.isnan(p_val):\n",
    "            kruskal_results[f\"{cat_var}_{num_var}\"] = p_val\n",
    "            print(f\"  {cat_var} vs {num_var} (p-valor): {p_val}\")\n",
    "        else:\n",
    "            print(f\"  {cat_var} vs {num_var}: No se pudo calcular el p-valor (ver advertencias anteriores o datos insuficientes).\")\n",
    "\n",
    "# Mostrar resultados finales\n",
    "print(\"\\n--- Resumen de los p-valores del test de Kruskal-Wallis ---\")\n",
    "if kruskal_results:\n",
    "    for key, p_val in kruskal_results.items():\n",
    "        print(f\"{key}: {p_val}\")\n",
    "else:\n",
    "    print(\"No se pudieron realizar tests de Kruskal-Wallis o no hay resultados para mostrar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961781d0",
   "metadata": {},
   "source": [
    "El resultado nos muestra el valor de p para el test, el cual ndica si hay una diferencia significativa entre las medianas de las variables numéricas en los diferentes grupos de las variables categóricas. Si el valor de p es pequeño (por lo general, menor a 0.05), se concluye que hay una diferencia significativa entre los grupos. Vemos que el valor de p es significativamente pequeño para todas las combinaciones de variables. Esto indica que la distribución de la variable numérica cambia significativamente entre los grupos de la variable categórica. Por lo tanto es útil tener todas las variables categóricas en el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e84470b",
   "metadata": {},
   "source": [
    "Por lo tanto, sabemos que las variables A y CIB tienen una correlación mayor a 80%, y que DBB y DOB tienen una correlación mayor al 70%, que CUS y OC tienen entre sí una asociación moderada, y que CUS y OC están asociadas de forma significativa a todas las variables numéricas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
