{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab3bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cuent\\En-Peu\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#os.chdir(\"C:/Users/cuent/En-Peu/notebooks/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71417b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64345 entries, 0 to 64344\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   POINT_X  64345 non-null  float64\n",
      " 1   POINT_Y  64345 non-null  float64\n",
      " 2   PLA      64345 non-null  float64\n",
      " 3   A        64345 non-null  float64\n",
      " 4   AC       64345 non-null  float64\n",
      " 5   CIB      64345 non-null  float64\n",
      " 6   CICCB    64345 non-null  float64\n",
      " 7   CUS      64345 non-null  int64  \n",
      " 8   DBB      64345 non-null  float64\n",
      " 9   DOB      64345 non-null  float64\n",
      " 10  OC       64345 non-null  int64  \n",
      " 11  P        64345 non-null  float64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 5.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cambiar al directorio padre\n",
    "os.chdir(\"..\")\n",
    "parent_directory = os.getcwd()\n",
    "\n",
    "# os.path.join() maneja correctamente las barras de ruta para diferentes SO (Windows, Linux, macOS)\n",
    "file_path = os.path.join(parent_directory, 'data', 'data_stored.csv')\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Verificar la estructura del DataFrame (equivalente a str(data) en R)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c670950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64345 entries, 0 to 64344\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   POINT_X  64345 non-null  float64 \n",
      " 1   POINT_Y  64345 non-null  float64 \n",
      " 2   PLA      64345 non-null  float64 \n",
      " 3   A        64345 non-null  float64 \n",
      " 4   AC       64345 non-null  float64 \n",
      " 5   CIB      64345 non-null  float64 \n",
      " 6   CICCB    64345 non-null  float64 \n",
      " 7   CUS      64345 non-null  category\n",
      " 8   DBB      64345 non-null  float64 \n",
      " 9   DOB      64345 non-null  float64 \n",
      " 10  OC       64345 non-null  category\n",
      " 11  P        64345 non-null  float64 \n",
      "dtypes: category(2), float64(10)\n",
      "memory usage: 5.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Podemos ver que CUS y OC no se están contando como categóricas. Hay que transformarlas\n",
    "data['CUS'] = data['CUS'].astype('category')\n",
    "data['OC'] = data['OC'].astype('category')\n",
    "# Verificar la estructura del DataFrame (equivalente a str(data) en R)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8536637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas a escalar (numéricas excluyendo coordenadas): ['PLA', 'A', 'AC', 'CIB', 'CICCB', 'DBB', 'DOB', 'P']\n"
     ]
    }
   ],
   "source": [
    "# --- Identificar variables numéricas excluyendo las coordenadas ---\n",
    "# Lista de columnas que se consideran coordenadas espaciales\n",
    "coordenadas = ['POINT_X', 'POINT_Y']\n",
    "\n",
    "# Seleccionar todas las columnas numéricas\n",
    "numericas = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Filtrar las columnas numéricas para excluir las coordenadas\n",
    "# Usamos un conjunto para una búsqueda eficiente de coordenadas\n",
    "cols_to_scale = [col for col in numericas if col not in set(coordenadas)]\n",
    "\n",
    "print(f\"\\nColumnas a escalar (numéricas excluyendo coordenadas): {cols_to_scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b953150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data después de usar sklearn MinMaxScaler:\n",
      "         POINT_X       POINT_Y  PLA         A        AC       CIB     CICCB  \\\n",
      "0  722396.507981  4.365860e+06  0.0  0.604254  0.067778  0.203910  0.390004   \n",
      "1  722404.245816  4.365860e+06  0.0  0.581583  1.000000  0.201362  0.388246   \n",
      "2  722411.983652  4.365860e+06  0.0  0.581583  1.000000  0.198815  0.386458   \n",
      "3  722396.502336  4.365868e+06  0.0  0.609629  1.000000  0.204328  0.391055   \n",
      "4  722404.240164  4.365868e+06  0.0  0.608561  1.000000  0.201762  0.389291   \n",
      "\n",
      "  CUS       DBB       DOB OC         P  \n",
      "0   5  0.620621  0.000000  4  0.077332  \n",
      "1   1  0.614835  0.788748  4  0.089864  \n",
      "2   1  0.610494  0.783177  4  0.089864  \n",
      "3   1  0.620342  0.000000  4  0.051674  \n",
      "4   1  0.614553  0.788748  4  0.062030  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Usar el MinMaxScaler de sklearn\n",
    "scaler = MinMaxScaler()\n",
    "# calcular min/max y escalar\n",
    "data[cols_to_scale] = scaler.fit_transform(data[cols_to_scale])\n",
    "\n",
    "# Guardar el objeto para poder tener el min/max en el futuro\n",
    "import joblib\n",
    "joblib.dump(scaler, os.path.join(parent_directory, 'data','min_max_scaler.pkl'))\n",
    "# To load later: \n",
    "# loaded_scaler = joblib.load(os.path.join(parent_directory, 'data','min_max_scaler.pkl'))\n",
    "# data_new_scaled = loaded_scaler.transform(data_new[cols_to_scale])\n",
    "print(\"Data después de usar sklearn MinMaxScaler:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da39340",
   "metadata": {},
   "source": [
    "Ahora hay que transformar las variables categóricas con One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e322f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data after sklearn OneHotEncoder:\n",
      "         POINT_X       POINT_Y  PLA         A        AC       CIB     CICCB  \\\n",
      "0  722396.507981  4.365860e+06  0.0  0.604254  0.067778  0.203910  0.390004   \n",
      "1  722404.245816  4.365860e+06  0.0  0.581583  1.000000  0.201362  0.388246   \n",
      "2  722411.983652  4.365860e+06  0.0  0.581583  1.000000  0.198815  0.386458   \n",
      "3  722396.502336  4.365868e+06  0.0  0.609629  1.000000  0.204328  0.391055   \n",
      "4  722404.240164  4.365868e+06  0.0  0.608561  1.000000  0.201762  0.389291   \n",
      "\n",
      "        DBB       DOB         P  CUS_1  CUS_2  CUS_3  CUS_4  CUS_5  OC_1  \\\n",
      "0  0.620621  0.000000  0.077332    0.0    0.0    0.0    0.0    1.0   0.0   \n",
      "1  0.614835  0.788748  0.089864    1.0    0.0    0.0    0.0    0.0   0.0   \n",
      "2  0.610494  0.783177  0.089864    1.0    0.0    0.0    0.0    0.0   0.0   \n",
      "3  0.620342  0.000000  0.051674    1.0    0.0    0.0    0.0    0.0   0.0   \n",
      "4  0.614553  0.788748  0.062030    1.0    0.0    0.0    0.0    0.0   0.0   \n",
      "\n",
      "   OC_2  OC_3  OC_4  \n",
      "0   0.0   0.0   1.0  \n",
      "1   0.0   0.0   1.0  \n",
      "2   0.0   0.0   1.0  \n",
      "3   0.0   0.0   1.0  \n",
      "4   0.0   0.0   1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols = ['CUS', 'OC']\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # sparse_output=False for dense array, handle_unknown='ignore' for new categories\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "encoded_features = encoder.fit_transform(data[categorical_cols])\n",
    "\n",
    "# Create a DataFrame from the encoded features\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original columns and concatenate new encoded columns\n",
    "data_encoded_sklearn = data.drop(columns=categorical_cols)\n",
    "data_encoded_sklearn = pd.concat([data_encoded_sklearn, encoded_df], axis=1)\n",
    "\n",
    "print(\"\\nData after sklearn OneHotEncoder:\")\n",
    "print(data_encoded_sklearn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e221d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame combinado guardado exitosamente como 'data_fin.csv' en 'C:\\Users\\cuent\\En-Peu\\data\\data_fin.csv'\n"
     ]
    }
   ],
   "source": [
    "# Guardar el resultado en un nuevo CSV\n",
    "nombre_archivo_salida = \"data_fin.csv\"\n",
    "data_encoded_sklearn.to_csv(os.path.join(parent_directory,'data',nombre_archivo_salida), index=False) # index=False evita guardar el índice de pandas como una columna\n",
    "\n",
    "print(f\"\\nDataFrame combinado guardado exitosamente como '{nombre_archivo_salida}' en '{os.path.join(parent_directory,'data',nombre_archivo_salida)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9a8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
