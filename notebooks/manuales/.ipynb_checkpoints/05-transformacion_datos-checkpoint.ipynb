{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b073cf7",
   "metadata": {},
   "source": [
    "Hay que normalizar los datos numéricos y transformar los datos categóricos para poder utilizarlos en los modelos. Utilizar *Min-Max Scaling* escala los datos en un rango [0,1], sirve para cualquier distribución, y se usa mucho en algunos modelos de aprendizaje automático. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b78e7de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cuent\\En-Peu\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#os.chdir(\"C:/Users/cuent/En-Peu/notebooks/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52615dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64345 entries, 0 to 64344\n",
      "Data columns (total 12 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   POINT_X  64345 non-null  float64\n",
      " 1   POINT_Y  64345 non-null  float64\n",
      " 2   PLA      64345 non-null  float64\n",
      " 3   A        64345 non-null  float64\n",
      " 4   AC       64345 non-null  float64\n",
      " 5   CIB      64345 non-null  float64\n",
      " 6   CICCB    64345 non-null  float64\n",
      " 7   CUS      64345 non-null  int64  \n",
      " 8   DBB      64345 non-null  float64\n",
      " 9   DOB      64345 non-null  float64\n",
      " 10  OC       64345 non-null  int64  \n",
      " 11  P        64345 non-null  float64\n",
      "dtypes: float64(10), int64(2)\n",
      "memory usage: 5.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cambiar al directorio padre\n",
    "os.chdir(\"..\")\n",
    "parent_directory = os.getcwd()\n",
    "\n",
    "# os.path.join() maneja correctamente las barras de ruta para diferentes SO (Windows, Linux, macOS)\n",
    "file_path = os.path.join(parent_directory, 'data', 'data_stored.csv')\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Verificar la estructura del DataFrame (equivalente a str(data) en R)\n",
    "print(data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b481ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas a escalar (numéricas excluyendo coordenadas): ['PLA', 'A', 'AC', 'CIB', 'CICCB', 'DBB', 'DOB', 'P']\n"
     ]
    }
   ],
   "source": [
    "# Podemos ver que CUS y OC no se están contando como categóricas. Hay que transformarlas\n",
    "data['CUS'] = data['CUS'].astype('category')\n",
    "data['OC'] = data['OC'].astype('category')\n",
    "\n",
    "# --- Identificar variables numéricas excluyendo las coordenadas ---\n",
    "# Lista de columnas que se consideran coordenadas espaciales\n",
    "coordenadas = ['POINT_X', 'POINT_Y']\n",
    "\n",
    "# Seleccionar todas las columnas numéricas\n",
    "numericas = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Filtrar las columnas numéricas para excluir las coordenadas\n",
    "# Usamos un conjunto para una búsqueda eficiente de coordenadas\n",
    "cols_to_scale = [col for col in numericas if col not in set(coordenadas)]\n",
    "\n",
    "print(f\"\\nColumnas a escalar (numéricas excluyendo coordenadas): {cols_to_scale}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2136a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores Min y Max calculados:\n",
      "            min          max\n",
      "PLA    0.000000     9.280740\n",
      "A      0.000000    29.951000\n",
      "AC     3.000000   225.050000\n",
      "CIB    0.098358     0.949654\n",
      "CICCB  0.100001     0.999806\n",
      "DBB    0.000000  1379.209961\n",
      "DOB    0.000000  1407.369995\n",
      "P      0.000000    28.388219\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Calcular Min y Max para las variables a escalar ---\n",
    "# Almacenamos estos valores en un DataFrame para su fácil guardado\n",
    "min_max_values = pd.DataFrame({\n",
    "    'min': data[cols_to_scale].min(),\n",
    "    'max': data[cols_to_scale].max()\n",
    "})\n",
    "\n",
    "print(\"\\nValores Min y Max calculados:\")\n",
    "print(min_max_values)\n",
    "\n",
    "min_max_values.to_csv(os.path.join(parent_directory, 'data', \"min_max_values.csv\"), index=True) # index=True para guardar los nombres de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e288a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min-Max Scaling aplicado a las variables numéricas (excepto coordenadas).\n",
      "\n",
      "Estadísticas del DataFrame escalado (primeras 5 filas):\n",
      "         POINT_X       POINT_Y  PLA         A        AC       CIB     CICCB  \\\n",
      "0  722396.507981  4.365860e+06  0.0  0.604254  0.067778  0.203910  0.390004   \n",
      "1  722404.245816  4.365860e+06  0.0  0.581583  1.000000  0.201362  0.388246   \n",
      "2  722411.983652  4.365860e+06  0.0  0.581583  1.000000  0.198815  0.386458   \n",
      "3  722396.502336  4.365868e+06  0.0  0.609629  1.000000  0.204328  0.391055   \n",
      "4  722404.240164  4.365868e+06  0.0  0.608561  1.000000  0.201762  0.389291   \n",
      "\n",
      "  CUS       DBB       DOB OC         P  \n",
      "0   5  0.620621  0.000000  4  0.077332  \n",
      "1   1  0.614835  0.788748  4  0.089864  \n",
      "2   1  0.610494  0.783177  4  0.089864  \n",
      "3   1  0.620342  0.000000  4  0.051674  \n",
      "4   1  0.614553  0.788748  4  0.062030  \n",
      "\n",
      "Estadísticas del DataFrame escalado (summary):\n",
      "             POINT_X       POINT_Y           PLA             A            AC  \\\n",
      "count   64345.000000  6.434500e+04  64345.000000  64345.000000  64345.000000   \n",
      "mean   722735.059375  4.367229e+06      0.143848      0.662481      0.452260   \n",
      "std       510.233372  6.609071e+02      0.070027      0.090739      0.380047   \n",
      "min    721505.463445  4.365815e+06      0.000000      0.000000      0.000000   \n",
      "25%    722341.239886  4.366685e+06      0.100655      0.588995      0.101554   \n",
      "50%    722758.250318  4.367264e+06      0.138280      0.652566      0.324476   \n",
      "75%    723169.751475  4.367756e+06      0.186247      0.725452      1.000000   \n",
      "max    723641.004170  4.368481e+06      1.000000      1.000000      1.000000   \n",
      "\n",
      "                CIB         CICCB           DBB           DOB             P  \n",
      "count  64345.000000  64345.000000  64345.000000  64345.000000  64345.000000  \n",
      "mean       0.378389      0.395269      0.300740      0.432758      0.046539  \n",
      "std        0.294368      0.186161      0.206911      0.209766      0.060794  \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "25%        0.076657      0.255409      0.129701      0.268905      0.016420  \n",
      "50%        0.378417      0.378011      0.273206      0.432991      0.030775  \n",
      "75%        0.662369      0.517333      0.436889      0.595916      0.054497  \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# --- 3. Aplicar Min-Max Scaling a las variables seleccionadas ---\n",
    "# La fórmula es (x - min) / (max - min)\n",
    "# Esto se hace de forma eficiente para todas las columnas de una vez.\n",
    "for col in cols_to_scale:\n",
    "    min_val = min_max_values.loc[col, 'min']\n",
    "    max_val = min_max_values.loc[col, 'max']\n",
    "    # Evitar división por cero si max == min (lo que significa que todos los valores son iguales)\n",
    "    if (max_val - min_val) != 0:\n",
    "        data[col] = (data[col] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        # Si todos los valores son iguales, la escala min-max los convierte en 0 o 0.5 (convención)\n",
    "        # Aquí los mantenemos en 0 si es el caso, o 0.5 si quieres un punto medio\n",
    "        data[col] = 0.0 # O np.nan si prefieres marcarlo como indefinido para la escala.\n",
    "\n",
    "print(\"\\nMin-Max Scaling aplicado a las variables numéricas (excepto coordenadas).\")\n",
    "\n",
    "# --- 4. Mostrar un resumen de los datos escalados ---\n",
    "print(\"\\nEstadísticas del DataFrame escalado (primeras 5 filas):\")\n",
    "print(data.head())\n",
    "print(\"\\nEstadísticas del DataFrame escalado (summary):\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961795ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
