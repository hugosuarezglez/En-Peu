data <- full_join(data, df, by = columnas_comunes)  # Une por esas columnas
}
}
# Mostrar las primeras filas de data
print(head(data,4))
# Ver si hay valores faltantes en este punto
print(table(is.na(data)))
# Guardar data en un dataframe por si acaso
data_stored <- data
# Cargar el nuevo CSV PLA con separador ";" y decimales con ","
archivo_nuevo <- "C:/Yo/MAtriX/variables/PLA/PAL_Crudo.csv"
df_nuevo <- read.csv(archivo_nuevo)
# Seleccionar las coordenadas y la columna grid_cod, renombrándola como PLA
df_nuevo <- df_nuevo %>% select(POINT_X, POINT_Y, Value) %>% rename(PLA = Value)
# Convertir coordenadas a un mismo tipo (por ejemplo, numérico)
df_nuevo <- df_nuevo %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
data <- data %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
coordenadas_comunes <- left_join(data %>% select(POINT_X, POINT_Y), df_nuevo %>% select(POINT_X, POINT_Y), by = c("POINT_X", "POINT_Y"))
print(paste("Número de coordenadas coincidentes:", nrow(coordenadas_comunes)))
# Unir el nuevo CSV con data
data <- inner_join(data, df_nuevo, by = c("POINT_X", "POINT_Y"))
# Reordenar las columnas para que PLA sea la cuarta
columnas_ordenadas <- c("POINT_X", "POINT_Y", setdiff(names(data), c("POINT_X", "POINT_Y")))
data <- data[, columnas_ordenadas]
# Mostrar las primeras filas del dataset combinado
print(head(data))
table(is.na(data))
# Guardar el resultado en un nuevo CSV
write_csv(data, "datos_combinados.csv")
str(data)
# Transformar variables en categóricas
data <- data %>% mutate(across(c(AC, CUS, OC, P), as.factor))
str(data)
table(is.na(data))
# Verificar si grid_cod es único
if (n_distinct(data$grid_cod) == nrow(data)) {
# Si es único, usarlo como índice y eliminar la columna
rownames(data) <- data$grid_cod
data <- select(data, -grid_cod)
message("grid_cod es único y se ha usado como índice.")
} else {
# Si no es único, eliminarlo directamente
data <- select(data, -grid_cod)
message("grid_cod no es único y se ha eliminado.")
}
# Mostrar las primeras filas del dataset transformado
head(data)
summary(data)  # Resumen estadístico
# Eliminar filas donde PLA es -9999
data <- data %>%
filter(PLA != -9999)
summary(data)
knitr::opts_chunk$set(echo = TRUE, comment = NULL, cache = TRUE)
library(knitr)
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)  # Para los gráficos
library(caret)    # Para los modelos
library(fastDummies)  # Para One-Hot Encoding
# Ruta de la carpeta donde están los archivos CSV
carpeta <- "C:/Yo/MAtriX/variables"
# Para leer todos los archivos csv dentro de esa carpeta
archivos <- list.files(path = carpeta, pattern = "*.csv", full.names = TRUE)
# Leer y combinar los archivos 1 por 1
data <- NULL
for (archivo in archivos) {
df <- read_csv(archivo)
# El valor de la variable se llama Value, y está siempre en la ultima columna
# entonces: renombrar la última columna usando el prefijo antes del "–"
nuevo_nombre <- gsub(" .*", "", gsub("–.*", "", basename(archivo)))
nuevo_nombre <- gsub(" ", "", nuevo_nombre)  # Elimina espacios
if (length(names(df)) > 0) {
names(df)[length(names(df))] <- nuevo_nombre  # Renombra la última columna
print(paste0(nuevo_nombre," Numero de datos: ",nrow(df)))
}
if (is.null(data)) {
data <- df  # Si es el primer archivo, se asigna directamente
} else {
columnas_comunes <- intersect(names(data), names(df))  # Ccolumnas comunes
data <- full_join(data, df, by = columnas_comunes)  # Une por esas columnas
}
}
# Mostrar las primeras filas de data
print(head(data,4))
# Ver si hay valores faltantes en este punto
print(table(is.na(data)))
# Guardar data en un dataframe por si acaso
data_stored <- data
# Cargar el nuevo CSV PLA con separador ";" y decimales con ","
archivo_nuevo <- "C:/Yo/MAtriX/variables/PLA/PAL_Crudo.csv"
df_nuevo <- read.csv(archivo_nuevo)
# Seleccionar las coordenadas y la columna grid_cod, renombrándola como PLA
df_nuevo <- df_nuevo %>% select(POINT_X, POINT_Y, Value) %>% rename(PLA = Value)
# Convertir coordenadas a un mismo tipo (por ejemplo, numérico)
df_nuevo <- df_nuevo %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
data <- data %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
coordenadas_comunes <- left_join(data %>% select(POINT_X, POINT_Y), df_nuevo %>% select(POINT_X, POINT_Y), by = c("POINT_X", "POINT_Y"))
print(paste("Número de coordenadas coincidentes:", nrow(coordenadas_comunes)))
# Unir el nuevo CSV con data
data <- inner_join(data, df_nuevo, by = c("POINT_X", "POINT_Y"))
# Reordenar las columnas para que PLA sea la cuarta
columnas_ordenadas <- c("POINT_X", "POINT_Y", setdiff(names(data), c("POINT_X", "POINT_Y")))
data <- data[, columnas_ordenadas]
# Mostrar las primeras filas del dataset combinado
print(head(data))
table(is.na(data))
# Guardar el resultado en un nuevo CSV
write_csv(data, "datos_combinados.csv")
str(data)
# Transformar variables en categóricas
data <- data %>% mutate(across(c(AC, CUS, OC, P), as.factor))
str(data)
table(is.na(data))
# Verificar si grid_cod es único
if (n_distinct(data$grid_cod) == nrow(data)) {
# Si es único, usarlo como índice y eliminar la columna
rownames(data) <- data$grid_cod
data <- select(data, -grid_cod)
message("grid_cod es único y se ha usado como índice.")
} else {
# Si no es único, eliminarlo directamente
data <- select(data, -grid_cod)
message("grid_cod no es único y se ha eliminado.")
}
# Mostrar las primeras filas del dataset transformado
head(data)
summary(data)  # Resumen estadístico
# Eliminar filas donde PLA es -9999
data <- data %>%
filter(PLA != -9999)
summary(data)
# Eliminar filas donde PLA es -9999
data <- data %>%
filter(PLA != -9999)
# Eliminar filas donde PLA es -9999
data <- data %>%
filter("PLA" != -9999)
summary(data)
View(data)
View(data)
knitr::opts_chunk$set(echo = TRUE, comment = NULL, cache = TRUE)
library(knitr)
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)  # Para los gráficos
library(caret)    # Para los modelos
library(fastDummies)  # Para One-Hot Encoding
# Ruta de la carpeta donde están los archivos CSV
carpeta <- "C:/Yo/MAtriX/variables"
# Para leer todos los archivos csv dentro de esa carpeta
archivos <- list.files(path = carpeta, pattern = "*.csv", full.names = TRUE)
# Leer y combinar los archivos 1 por 1
data <- NULL
for (archivo in archivos) {
df <- read_csv(archivo)
# El valor de la variable se llama Value, y está siempre en la ultima columna
# entonces: renombrar la última columna usando el prefijo antes del "–"
nuevo_nombre <- gsub(" .*", "", gsub("–.*", "", basename(archivo)))
nuevo_nombre <- gsub(" ", "", nuevo_nombre)  # Elimina espacios
if (length(names(df)) > 0) {
names(df)[length(names(df))] <- nuevo_nombre  # Renombra la última columna
print(paste0(nuevo_nombre," Numero de datos: ",nrow(df)))
}
if (is.null(data)) {
data <- df  # Si es el primer archivo, se asigna directamente
} else {
columnas_comunes <- intersect(names(data), names(df))  # Ccolumnas comunes
data <- full_join(data, df, by = columnas_comunes)  # Une por esas columnas
}
}
# Mostrar las primeras filas de data
print(head(data,4))
# Ver si hay valores faltantes en este punto
print(table(is.na(data)))
# Guardar data en un dataframe por si acaso
data_stored <- data
# Cargar el nuevo CSV PLA con separador ";" y decimales con ","
archivo_nuevo <- "C:/Yo/MAtriX/variables/PLA/PAL_Crudo.csv"
df_nuevo <- read.csv(archivo_nuevo)
# Seleccionar las coordenadas y la columna grid_cod, renombrándola como PLA
df_nuevo <- df_nuevo %>% select(POINT_X, POINT_Y, Value) %>% rename(PLA = Value)
# Convertir coordenadas a un mismo tipo (por ejemplo, numérico)
df_nuevo <- df_nuevo %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
data <- data %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
coordenadas_comunes <- left_join(data %>% select(POINT_X, POINT_Y), df_nuevo %>% select(POINT_X, POINT_Y), by = c("POINT_X", "POINT_Y"))
print(paste("Número de coordenadas coincidentes:", nrow(coordenadas_comunes)))
# Unir el nuevo CSV con data
data <- inner_join(data, df_nuevo, by = c("POINT_X", "POINT_Y"))
# Reordenar las columnas para que PLA sea la cuarta
columnas_ordenadas <- c("POINT_X", "POINT_Y", setdiff(names(data), c("POINT_X", "POINT_Y")))
data <- data[, columnas_ordenadas]
# Mostrar las primeras filas del dataset combinado
print(head(data))
table(is.na(data))
# Guardar el resultado en un nuevo CSV
write_csv(data, "datos_combinados.csv")
str(data)
# Transformar variables en categóricas
data <- data %>% mutate(across(c(AC, CUS, OC, P), as.factor))
str(data)
table(is.na(data))
# Verificar si grid_cod es único
if (n_distinct(data$grid_cod) == nrow(data)) {
# Si es único, usarlo como índice y eliminar la columna
rownames(data) <- data$grid_cod
data <- select(data, -grid_cod)
message("grid_cod es único y se ha usado como índice.")
} else {
# Si no es único, eliminarlo directamente
data <- select(data, -grid_cod)
message("grid_cod no es único y se ha eliminado.")
}
# Mostrar las primeras filas del dataset transformado
head(data)
summary(data)  # Resumen estadístico
# Eliminar filas donde PLA es -9999
data <- data %>%
filter("PLA" != -9999)
summary(data)
# Función para reemplazar -9999 con la mediana (o la media)
reemplazar_neg9999 <- function(x, metodo = "mediana") {
if (is.numeric(x)) {
x[x == -9999] <- if (metodo == "media") mean(x[x != -9999],
na.rm = TRUE) else
if (metodo == "moda")
as.numeric(names(sort(table(x[x != -9999]),
decreasing = TRUE)[1])) else
median(x[x != -9999], na.rm = TRUE)  # Mediana por defecto
}
return(x)
}
# Aplicar la transformación a todas las columnas numéricas del dataset
data <- data %>%
mutate(across(where(is.numeric), ~ reemplazar_neg9999(.x, metodo = "mediana")))
summary(data)
# Seleccionar solo las variables numéricas
data_num <- data %>% select(where(is.numeric)) %>%
pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
# Histograma de todas las variables numéricas
ggplot(data_num, aes(x = Valor)) +
geom_histogram(bins = 30, fill = "blue", alpha = 0.5, color = "black") +
facet_wrap(~ Variable, scales = "free") +  # Un gráfico por variable
theme_minimal() +
labs(title = "Histogramas de las variables numéricas",
x = "Valor", y = "Frecuencia")
# Boxplot separado por variable
ggplot(data_num, aes(y = Valor)) +
geom_boxplot(fill = "red", alpha = 0.5, outlier.color = "black",
outlier.shape = 16) +
facet_wrap(~ Variable, scales = "free") +  # Separar cada boxplot
theme_minimal() +
labs(title = "Boxplots de las variables numéricas", y = "Valor")
# Variables que NO queremos transformar (coordenadas espaciales)
vars_excluir <- c("POINT_X", "POINT_Y")
# Aplicar Min-Max Scaling a todas las variables numéricas excepto las coordenadas
data <- data %>%
mutate(across(where(is.numeric) & !all_of(vars_excluir),
~ (.-min(.))/(max(.)-min(.))
))
#message("Se ha aplicado Min-Max Scaling a todas las variables numéricas
# excepto las coordenadas espaciales.")
summary(data)
table(data$AC)
table(data$P)
# Convertir los datos a numericos para hacer Label Encoding
data <- data %>%
mutate(
AC = as.integer(AC),  # Convierte el factor ordenado en números manteniendo el orden
P = as.integer(P)      # Lo mismo para P
)
# Aplicar One-Hot Encoding a CUS y OC
data <- dummy_cols(data, select_columns = c("CUS", "OC"), remove_selected_columns = TRUE)
setwd("C:/Yo/MAtriX/variables")
data$PLA
# Numero de filas y columnas
nrow <- nrow(data)
ncol <- ncol(data)
# Porcentaje para dividir los datos en train/test
perc = 0.7
# Establecer la semilla
seed <- 12345
# Reordenar columnas: dejar POINT_X y POINT_Y primero, luego PLA, y después el resto
data <- data %>%
select(POINT_X, POINT_Y, PLA, everything())
knitr::opts_chunk$set(echo = TRUE)
# Ruta de la carpeta donde están los archivos CSV
carpeta <- "C:/Yo/MAtriX/variables"
# Para leer todos los archivos csv dentro de esa carpeta
archivos <- list.files(path = carpeta, pattern = "*.csv", full.names = TRUE)
# Leer y combinar los archivos 1 por 1
data <- NULL
for (archivo in archivos) {
df <- read_csv(archivo)
# El valor de la variable se llama Value, y está siempre en la ultima columna
# entonces: renombrar la última columna usando el prefijo antes del "–"
nuevo_nombre <- gsub(" .*", "", gsub("–.*", "", basename(archivo)))
nuevo_nombre <- gsub(" ", "", nuevo_nombre)  # Elimina espacios
if (length(names(df)) > 0) {
names(df)[length(names(df))] <- nuevo_nombre  # Renombra la última columna
print(paste0(nuevo_nombre," Numero de datos: ",nrow(df)))
}
if (is.null(data)) {
data <- df  # Si es el primer archivo, se asigna directamente
} else {
columnas_comunes <- intersect(names(data), names(df))  # Ccolumnas comunes
data <- full_join(data, df, by = columnas_comunes)  # Une por esas columnas
}
}
# Mostrar las primeras filas de data
print(head(data,4))
# Ver si hay valores faltantes en este punto
print(table(is.na(data)))
# Guardar data en un dataframe por si acaso
data_stored <- data
# Cargar el nuevo CSV PLA con separador ";" y decimales con ","
archivo_nuevo <- "C:/Yo/MAtriX/variables/PLA/PAL_Crudo.csv"
df_nuevo <- read.csv(archivo_nuevo)
# Seleccionar las coordenadas y la columna grid_cod, renombrándola como PLA
df_nuevo <- df_nuevo %>% select(POINT_X, POINT_Y, Value) %>% rename(PLA = Value)
# Convertir coordenadas a un mismo tipo (por ejemplo, numérico)
df_nuevo <- df_nuevo %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
data <- data %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
coordenadas_comunes <- left_join(data %>% select(POINT_X, POINT_Y), df_nuevo %>% select(POINT_X, POINT_Y), by = c("POINT_X", "POINT_Y"))
print(paste("Número de coordenadas coincidentes:", nrow(coordenadas_comunes)))
# Unir el nuevo CSV con data
data <- inner_join(data, df_nuevo, by = c("POINT_X", "POINT_Y"))
# Reordenar las columnas para que PLA sea la cuarta
columnas_ordenadas <- c("POINT_X", "POINT_Y", "PLA", setdiff(names(data), c("POINT_X", "POINT_Y", "PLA")))
data <- data[, columnas_ordenadas]
# Mostrar las primeras filas del dataset combinado
print(head(data))
table(is.na(data))
# Guardar el resultado en un nuevo CSV
write_csv(data, "datos_combinados.csv")
View(data)
knitr::opts_chunk$set(echo = TRUE, comment = NULL, cache = TRUE)
library(knitr)
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)  # Para los gráficos
library(caret)    # Para los modelos
library(fastDummies)  # Para One-Hot Encoding
# Ruta de la carpeta donde están los archivos CSV
carpeta <- "C:/Yo/MAtriX/variables"
# Para leer todos los archivos csv dentro de esa carpeta
archivos <- list.files(path = carpeta, pattern = "*.csv", full.names = TRUE)
# Leer y combinar los archivos 1 por 1
data <- NULL
for (archivo in archivos) {
df <- read_csv(archivo)
# El valor de la variable se llama Value, y está siempre en la ultima columna
# entonces: renombrar la última columna usando el prefijo antes del "–"
nuevo_nombre <- gsub(" .*", "", gsub("–.*", "", basename(archivo)))
nuevo_nombre <- gsub(" ", "", nuevo_nombre)  # Elimina espacios
if (length(names(df)) > 0) {
names(df)[length(names(df))] <- nuevo_nombre  # Renombra la última columna
print(paste0(nuevo_nombre," Numero de datos: ",nrow(df)))
}
if (is.null(data)) {
data <- df  # Si es el primer archivo, se asigna directamente
} else {
columnas_comunes <- intersect(names(data), names(df))  # Ccolumnas comunes
data <- full_join(data, df, by = columnas_comunes)  # Une por esas columnas
}
}
# Mostrar las primeras filas de data
print(head(data,4))
# Ver si hay valores faltantes en este punto
print(table(is.na(data)))
# Guardar data en un dataframe por si acaso
data_stored <- data
# Cargar el nuevo CSV PLA con separador ";" y decimales con ","
archivo_nuevo <- "C:/Yo/MAtriX/variables/PLA/PAL_Crudo.csv"
df_nuevo <- read.csv(archivo_nuevo)
# Seleccionar las coordenadas y la columna grid_cod, renombrándola como PLA
df_nuevo <- df_nuevo %>% select(POINT_X, POINT_Y, Value) %>% rename(PLA = Value)
# Convertir coordenadas a un mismo tipo (por ejemplo, numérico)
df_nuevo <- df_nuevo %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
data <- data %>%
mutate(POINT_X = as.numeric(POINT_X),
POINT_Y = as.numeric(POINT_Y))
coordenadas_comunes <- left_join(data %>% select(POINT_X, POINT_Y), df_nuevo %>% select(POINT_X, POINT_Y), by = c("POINT_X", "POINT_Y"))
print(paste("Número de coordenadas coincidentes:", nrow(coordenadas_comunes)))
# Unir el nuevo CSV con data
data <- inner_join(data, df_nuevo, by = c("POINT_X", "POINT_Y"))
# Reordenar las columnas para que PLA sea la cuarta
columnas_ordenadas <- c("POINT_X", "POINT_Y", "PLA", setdiff(names(data), c("POINT_X", "POINT_Y", "PLA")))
data <- data[, columnas_ordenadas]
# Mostrar las primeras filas del dataset combinado
print(head(data))
table(is.na(data))
# Guardar el resultado en un nuevo CSV
write_csv(data, "datos_combinados.csv")
str(data)
# Transformar variables en categóricas
data <- data %>% mutate(across(c(AC, CUS, OC, P), as.factor))
str(data)
table(is.na(data))
# Verificar si grid_cod es único
if (n_distinct(data$grid_cod) == nrow(data)) {
# Si es único, usarlo como índice y eliminar la columna
rownames(data) <- data$grid_cod
data <- select(data, -grid_cod)
message("grid_cod es único y se ha usado como índice.")
} else {
# Si no es único, eliminarlo directamente
data <- select(data, -grid_cod)
message("grid_cod no es único y se ha eliminado.")
}
# Mostrar las primeras filas del dataset transformado
head(data)
summary(data)  # Resumen estadístico
# Eliminar filas donde PLA es -9999
data <- data %>%
filter("PLA" != -9999)
summary(data)
# Función para reemplazar -9999 con la mediana (o la media)
reemplazar_neg9999 <- function(x, metodo = "mediana") {
if (is.numeric(x)) {
x[x == -9999] <- if (metodo == "media") mean(x[x != -9999],
na.rm = TRUE) else
if (metodo == "moda")
as.numeric(names(sort(table(x[x != -9999]),
decreasing = TRUE)[1])) else
median(x[x != -9999], na.rm = TRUE)  # Mediana por defecto
}
return(x)
}
# Aplicar la transformación a todas las columnas numéricas del dataset
data <- data %>%
mutate(across(where(is.numeric), ~ reemplazar_neg9999(.x, metodo = "mediana")))
summary(data)
# Seleccionar solo las variables numéricas
data_num <- data %>% select(where(is.numeric)) %>%
pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")
# Histograma de todas las variables numéricas
ggplot(data_num, aes(x = Valor)) +
geom_histogram(bins = 30, fill = "blue", alpha = 0.5, color = "black") +
facet_wrap(~ Variable, scales = "free") +  # Un gráfico por variable
theme_minimal() +
labs(title = "Histogramas de las variables numéricas",
x = "Valor", y = "Frecuencia")
# Boxplot separado por variable
ggplot(data_num, aes(y = Valor)) +
geom_boxplot(fill = "red", alpha = 0.5, outlier.color = "black",
outlier.shape = 16) +
facet_wrap(~ Variable, scales = "free") +  # Separar cada boxplot
theme_minimal() +
labs(title = "Boxplots de las variables numéricas", y = "Valor")
# Variables que NO queremos transformar (coordenadas espaciales)
vars_excluir <- c("POINT_X", "POINT_Y")
# Aplicar Min-Max Scaling a todas las variables numéricas excepto las coordenadas
data <- data %>%
mutate(across(where(is.numeric) & !all_of(vars_excluir),
~ (.-min(.))/(max(.)-min(.))
))
#message("Se ha aplicado Min-Max Scaling a todas las variables numéricas
# excepto las coordenadas espaciales.")
summary(data)
table(data$AC)
table(data$P)
# Convertir los datos a numericos para hacer Label Encoding
data <- data %>%
mutate(
AC = as.integer(AC),  # Convierte el factor ordenado en números manteniendo el orden
P = as.integer(P)      # Lo mismo para P
)
# Aplicar One-Hot Encoding a CUS y OC
data <- dummy_cols(data, select_columns = c("CUS", "OC"), remove_selected_columns = TRUE)
setwd("C:/Yo/MAtriX/variables")
# Cargar datos
# data <- read.csv("datos_combinados", sep=',', header=F)
# Numero de filas y columnas
nrow <- nrow(data)
ncol <- ncol(data)
# Porcentaje para dividir los datos en train/test
perc = 0.7
# Establecer la semilla
seed <- 12345
# Etiquetas
resp <- data[,3]
head(resp,5)
set.seed(seed)
# Con sample sacamos los indices con los que obtenemos los datos de train
train_indices <- sample(nrow(data), floor(perc * nrow(data)))
data_train <- data[train_indices, ]  # Datos para train
data_test <- data[-train_indices, ]  # Datos para test
# Como al normalizar no usamos la columna Uva, no tenemos las etiquetas en
# train y test. Ahora las guardamos:
data_train_labels <- data[train_indices, 3]
data_test_labels <- data[-train_indices, 3]
