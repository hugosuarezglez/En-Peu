{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc413e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Número de datos: 67212\n",
      "AC Número de datos: 67212\n",
      "B Número de datos: 67212\n",
      "CIB Número de datos: 67212\n",
      "CICCB Número de datos: 67212\n",
      "CUS Número de datos: 67212\n",
      "DBB Número de datos: 67212\n",
      "DOB Número de datos: 67212\n",
      "OC Número de datos: 67212\n",
      "P Número de datos: 67212\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ruta de la carpeta donde están los archivos CSV\n",
    "carpeta = \"D:/HUGO/MAtriX/variables\"\n",
    "\n",
    "# Para leer todos los archivos csv dentro de esa carpeta\n",
    "# Usamos os.path.join para construir rutas de forma segura en cualquier SO\n",
    "archivos = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith(\".csv\")]\n",
    "\n",
    "# Leer y combinar los archivos 1 por 1\n",
    "data = None\n",
    "\n",
    "for archivo in archivos:\n",
    "    df = pd.read_csv(archivo)\n",
    "\n",
    "    # El valor de la variable se llama Value, y está siempre en la ultima columna\n",
    "    # Renombrar la última columna usando el prefijo antes del \"–\"\n",
    "    # y eliminando espacios\n",
    "    nombre_base = os.path.basename(archivo)\n",
    "    # Extrae el prefijo antes del \"–\" o el primer espacio si \"–\" no existe\n",
    "    if '–' in nombre_base:\n",
    "        nuevo_nombre = nombre_base.split('–')[0].strip()\n",
    "    else:\n",
    "        nuevo_nombre = nombre_base.split(' ')[0].strip()\n",
    "\n",
    "    # Eliminar la extensión .csv si aún está presente\n",
    "    nuevo_nombre = nuevo_nombre.replace(\".csv\", \"\")\n",
    "    # Borrar espacios adicionales\n",
    "    nuevo_nombre = nuevo_nombre.replace(\" \", \"\")\n",
    "\n",
    "    if len(df.columns) > 0:\n",
    "        # Renombra la última columna\n",
    "        df.rename(columns={df.columns[-1]: nuevo_nombre}, inplace=True)\n",
    "        print(f\"{nuevo_nombre} Número de datos: {len(df)}\")\n",
    "\n",
    "    if data is None:\n",
    "        data = df  # Si es el primer archivo, se asigna directamente\n",
    "    else:\n",
    "        # Columnas comunes para la unión\n",
    "        columnas_comunes = list(set(data.columns) & set(df.columns))\n",
    "        # Une por esas columnas (full_join en pandas es merge con how='outer')\n",
    "        data = pd.merge(data, df, on=columnas_comunes, how='outer')\n",
    "\n",
    "# Ahora 'data' contiene el df combinado con las variables predictoras y las coordenadas\n",
    "# print(data.head(5)) # Descomentar para ver las primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200c2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_cod    0\n",
      "POINT_X     0\n",
      "POINT_Y     0\n",
      "A           0\n",
      "AC          0\n",
      "B           0\n",
      "CIB         0\n",
      "CICCB       0\n",
      "CUS         0\n",
      "DBB         0\n",
      "DOB         0\n",
      "OC          0\n",
      "P           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ver si hay valores faltantes en este punto\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3aedfb",
   "metadata": {},
   "source": [
    "Una vez se tienen las variables predictoras, se añade también la variable respuesta PLA (profundidad de la lámina de agua)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de640537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_cod        POINT_X       POINT_Y  Value\n",
      "0      6909  722404.251470  4.365852e+06    0.0\n",
      "1      7246  722396.507981  4.365860e+06    0.0\n",
      "2      7247  722404.245816  4.365860e+06    0.0\n",
      "3      7248  722411.983652  4.365860e+06    0.0\n"
     ]
    }
   ],
   "source": [
    "# Cargar el nuevo CSV PLA con separador \";\" y decimales con \",\"\n",
    "archivo_nuevo = \"D:/HUGO/MAtriX/variables/PLA/CSV_PLA_19_05_25.csv\"\n",
    "\n",
    "# Para leer un CSV con separador ';' y decimales ',' en pandas, usamos 'sep' y 'decimal'\n",
    "df_nuevo = pd.read_csv(archivo_nuevo, sep=',', decimal='.')\n",
    "print(df_nuevo.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afc6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las coordenadas y la columna Value, renombrándola como PLA\n",
    "# Usamos .loc para seleccionar columnas y .rename para renombrar\n",
    "df_nuevo = df_nuevo.loc[:, ['POINT_X', 'POINT_Y', 'Value']].rename(columns={'Value': 'PLA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8a2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de coordenadas coincidentes: 67212\n"
     ]
    }
   ],
   "source": [
    "# Convertir coordenadas a un mismo tipo (numérico)\n",
    "# Usamos .astype(float) para asegurar que sean números de punto flotante\n",
    "df_nuevo['POINT_X'] = df_nuevo['POINT_X'].astype(float)\n",
    "df_nuevo['POINT_Y'] = df_nuevo['POINT_Y'].astype(float)\n",
    "\n",
    "# Asumiendo que 'data' ya es un DataFrame de pandas de los pasos anteriores\n",
    "# Convertir coordenadas de 'data' a numérico también (si no lo están ya)\n",
    "data['POINT_X'] = data['POINT_X'].astype(float)\n",
    "data['POINT_Y'] = data['POINT_Y'].astype(float)\n",
    "\n",
    "# Realizar un left_join para encontrar coordenadas coincidentes\n",
    "# Seleccionamos las columnas de interés y luego usamos pd.merge con how='inner'\n",
    "# Un inner join es lo que necesitas para encontrar solo las filas que coinciden en ambos DataFrames.\n",
    "# Si solo quieres las coordenadas de 'data' que tienen coincidencia en 'df_nuevo',\n",
    "# un 'left' join sería adecuado, pero para 'coordenadas_comunes' que son las que *ambos* tienen, 'inner' es el camino.\n",
    "coordenadas_comunes = pd.merge(\n",
    "    data[['POINT_X', 'POINT_Y']],\n",
    "    df_nuevo[['POINT_X', 'POINT_Y']],\n",
    "    on=['POINT_X', 'POINT_Y'],\n",
    "    how='inner' # Para encontrar solo las coordenadas coincidentes\n",
    ")\n",
    "\n",
    "# Imprimir el número de coordenadas coincidentes\n",
    "print(f\"Número de coordenadas coincidentes: {len(coordenadas_comunes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee82d5",
   "metadata": {},
   "source": [
    "Vemos que las coordenadas coinciden con el número de datos que obtuvimos al principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67114e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del DataFrame combinado:\n",
      "         POINT_X       POINT_Y  PLA  grid_cod          A  AC  B          CIB  \\\n",
      "0  722404.251470  4.365852e+06  0.0      6909  17.955999  11  0 -9999.000000   \n",
      "1  722396.507981  4.365860e+06  0.0      7246  18.179501   4  0     0.271946   \n",
      "2  722404.245816  4.365860e+06  0.0      7247  18.274900  11  0     0.269777   \n",
      "\n",
      "      CICCB  CUS         DBB          DOB  OC         P  \n",
      "0  0.448429    1  848.570984     0.000000   4  4.771400  \n",
      "1  0.450929    5  855.966980     0.000000   4  1.352900  \n",
      "2  0.449347    1  847.986023  1110.060059   4  0.436232  \n",
      "\n",
      "Conteo de valores faltantes (NaN) en el DataFrame combinado:\n",
      "POINT_X     0\n",
      "POINT_Y     0\n",
      "PLA         0\n",
      "grid_cod    0\n",
      "A           0\n",
      "AC          0\n",
      "B           0\n",
      "CIB         0\n",
      "CICCB       0\n",
      "CUS         0\n",
      "DBB         0\n",
      "DOB         0\n",
      "OC          0\n",
      "P           0\n",
      "dtype: int64\n",
      "\n",
      "Conteo total de True/False para valores faltantes en todo el DataFrame:\n",
      "Total de valores faltantes (True): 0\n",
      "Total de valores no faltantes (False): 940968\n",
      "\n",
      "DataFrame combinado guardado exitosamente como 'datos_combinados.csv'\n"
     ]
    }
   ],
   "source": [
    "# Unir el nuevo CSV (df_nuevo) con data\n",
    "# Usamos pd.merge con how='inner' para el inner_join\n",
    "data = pd.merge(data, df_nuevo, on=['POINT_X', 'POINT_Y'], how='inner')\n",
    "\n",
    "# Reordenar las columnas para que PLA sea la tercera\n",
    "# Primero, definimos el orden deseado para las columnas principales\n",
    "columnas_principales = [\"POINT_X\", \"POINT_Y\", \"PLA\"]\n",
    "\n",
    "# Luego, obtenemos el resto de las columnas que no sean las principales,\n",
    "# manteniendo su orden original y asegurándonos de que 'PLA' esté ahora en 'data'\n",
    "otras_columnas = [col for col in data.columns if col not in columnas_principales]\n",
    "\n",
    "# Creamos la lista final de columnas en el orden deseado\n",
    "columnas_ordenadas = columnas_principales + otras_columnas\n",
    "\n",
    "# Reordenamos el DataFrame\n",
    "data = data[columnas_ordenadas]\n",
    "\n",
    "# Mostrar las primeras filas del dataset combinado\n",
    "print(\"Primeras filas del DataFrame combinado:\")\n",
    "print(data.head(3))\n",
    "\n",
    "# Ver si hay valores faltantes en este punto\n",
    "print(\"\\nConteo de valores faltantes (NaN) en el DataFrame combinado:\")\n",
    "print(data.isna().sum())\n",
    "\n",
    "print(\"\\nConteo total de True/False para valores faltantes en todo el DataFrame:\")\n",
    "total_faltantes = data.isna().sum().sum()\n",
    "total_no_faltantes = data.size - total_faltantes\n",
    "print(f\"Total de valores faltantes (True): {total_faltantes}\")\n",
    "print(f\"Total de valores no faltantes (False): {total_no_faltantes}\")\n",
    "\n",
    "\n",
    "# Guardar el resultado en un nuevo CSV\n",
    "# write_csv en R es to_csv en pandas\n",
    "nombre_archivo_salida = \"datos_combinados.csv\"\n",
    "data.to_csv(nombre_archivo_salida, index=False) # index=False evita guardar el índice de pandas como una columna\n",
    "\n",
    "print(f\"\\nDataFrame combinado guardado exitosamente como '{nombre_archivo_salida}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52150c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
